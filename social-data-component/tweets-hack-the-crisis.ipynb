{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hack the Crisis\n",
    "\n",
    "Twitter data component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dataset/swe_tweets.csv\")\n",
    "data['timestamp'] =  pd.to_datetime(data['timestamp'])\n",
    "data = data[['timestamp','tweet']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daydata = data.groupby([data['timestamp'].dt.date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day,data in daydata:\n",
    "    with open(\"docs/\" + str(day) + \".txt\", \"w\") as docfile:\n",
    "        for t in data.tweet:\n",
    "            docfile.write(str(t) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment scores per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare categorisation\n",
    "with open('scoring_tools/categories.pickle', 'rb') as handle:\n",
    "    category_dict = pickle.load(handle)\n",
    "with open('scoring_tools/wordfeatures.pickle', 'rb') as handle:\n",
    "    wordfeatures_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Swedish translation (only of the used categories)\n",
    "transl_df = pd.read_csv(\"scoring_tools/swe_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enwords = transl_df.en.tolist()\n",
    "swewords = transl_df.sv.tolist()\n",
    "transl_dict = dict(zip(enwords, swewords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swedish_scoring = {}\n",
    "\n",
    "for w in enwords:\n",
    "    k = transl_dict.get(w)\n",
    "    v = wordfeatures_dict.get(w)\n",
    "    swedish_scoring[k]=v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the daily docs\n",
    "days = [f.split(\"/\")[1].split(\".\")[0] for f in glob.glob(\"docs/*.txt\")]\n",
    "docs = [open(file,\"r\").read() for file in glob.glob(\"docs/*.txt\")]\n",
    "docs = [re.sub(\"\\n\",\" \",d) for d in docs]\n",
    "daydocs = pd.DataFrame(zip(days,docs))\n",
    "daydocs.columns=['day','text']\n",
    "daydocs = daydocs.sort_values(by=\"day\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = daydocs.day.tolist()\n",
    "docs = daydocs.text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for c,doc in enumerate(docs):\n",
    "    print(\"\\r\" + str(c+1) + \"/\" + str(len(docs)), end=\"\")\n",
    "        \n",
    "    data_dict = {}\n",
    "    \n",
    "    data_dict['doc'] = doc\n",
    "    doc = doc.split()\n",
    "    doc = [w.lower().strip() for w in doc]\n",
    "    doc = [re.sub(\"\\.|,|\\:|/|\\\"|\\?|-|â€¦|'|\\(|\\)|\\!|\\+\",\"\", w) for w in doc]\n",
    "\n",
    "    docfeatures = []\n",
    "    for w in doc:\n",
    "        if w in swedish_scoring:\n",
    "            feats = swedish_scoring[w]\n",
    "            try:\n",
    "                for f in feats:\n",
    "                    docfeatures.append(f)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    for df in docfeatures:\n",
    "        label = category_dict[df]\n",
    "        label = label.split()[0]\n",
    "        \n",
    "    counts = Counter(docfeatures)\n",
    "    for k,v in counts.items():\n",
    "        category = category_dict[k]\n",
    "        category = category.split()[0]\n",
    "        count = v\n",
    "        proportion_by_wordcount = (v/len(doc))*100 # this gives same scores as in LIWC's own software\n",
    "        \n",
    "        data_dict[category] = round(proportion_by_wordcount, 2)\n",
    "    \n",
    "    dataset.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame.from_records(dataset).fillna(0)\n",
    "scores_df['day'] = days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = scores_df[['day',\n",
    "                    'health',\n",
    "                    'death',\n",
    "                    'bio',\n",
    "                    'body',\n",
    "                    'affect',\n",
    "                    'anger',\n",
    "                    'swear',\n",
    "                    'anx',\n",
    "                    'sad',\n",
    "                    'feel',\n",
    "                    'friend',\n",
    "                    'family',\n",
    "                    'social',\n",
    "                    'money',\n",
    "                    'work',\n",
    "                    'relig',\n",
    "                    'power',\n",
    "                    'cause',\n",
    "                    'certain',\n",
    "                    'insight',\n",
    "                    'compare',\n",
    "                    'risk',\n",
    "                    'interrog',\n",
    "                    'focusfuture',\n",
    "                    'tentat',\n",
    "                    'quant']\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add VADER posemo and negemo\n",
    "posemo = []\n",
    "negemo = []\n",
    "\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for c,doc in enumerate(docs):\n",
    "    docpos = []\n",
    "    docneg = []\n",
    "    \n",
    "    sents = sent_tokenize(doc)\n",
    "    for sent in sents:\n",
    "        vs = analyzer.polarity_scores(sent)\n",
    "        docpos.append(vs.get('pos'))\n",
    "        docneg.append(vs.get('neg'))\n",
    "    docpos = sum(docpos)/len(docpos)\n",
    "    docneg = sum(docneg)/len(docneg)\n",
    "    posemo.append(docpos)\n",
    "    negemo.append(docneg)\n",
    "    print(\"\\r\" + str(c+1) + \"/\" + str(len(docs)), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df['posemo'] = posemo\n",
    "scores_df['negemo'] = negemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df[\"diseaseIndex\"] = scores_df.health+scores_df.death+scores_df.bio+scores_df.body\n",
    "scores_df[\"emotionIndex\"] = scores_df.negemo+scores_df.affect+scores_df.anger+scores_df.swear+scores_df.anx+scores_df.sad+scores_df.posemo+scores_df.feel\n",
    "scores_df[\"relationIndex\"] = scores_df.friend+scores_df.family+scores_df.social\n",
    "scores_df[\"economyIndex\"] = scores_df.money+scores_df.work\n",
    "scores_df[\"politicalIndex\"] = scores_df.relig+scores_df.power+scores_df.cause+scores_df.certain+scores_df.insight+scores_df.compare+scores_df.risk+scores_df.interrog+scores_df.focusfuture+scores_df.tentat+scores_df.quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_norm = list(scores_df.columns)\n",
    "cols_to_norm.remove('day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df[cols_to_norm] = scores_df[cols_to_norm].apply(lambda x: 2*(x - x.min()) / (x.max() - x.min())-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.posemo.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.insight.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.relationIndex.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.to_csv(\"tabular-data-output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse to fit frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = {}\n",
    "\n",
    "\n",
    "# the key to append to the dict\n",
    "for day in scores_df.day:\n",
    "    \n",
    "    dailydatadict = {}\n",
    "    \n",
    "    # ---------\n",
    "    dailydiseasedict = {}\n",
    "    for v in scores_df.diseaseIndex:\n",
    "        dailydiseasedict[\"diseaseIndex\"]=v\n",
    "    for v in scores_df.health:\n",
    "        dailydiseasedict[\"health\"]=v\n",
    "    for v in scores_df.death:\n",
    "        dailydiseasedict[\"death\"]=v\n",
    "    for v in scores_df.bio:\n",
    "        dailydiseasedict[\"bio\"]=v\n",
    "    for v in scores_df.body:\n",
    "        dailydiseasedict[\"body\"]=v\n",
    "    # ---------\n",
    "    dailyemotiondict = {}\n",
    "    for v in scores_df.emotionIndex:\n",
    "        dailyemotiondict[\"emotionIndex\"]=v\n",
    "    for v in scores_df.feel:\n",
    "        dailyemotiondict[\"feel\"]=v\n",
    "    for v in scores_df.negemo:\n",
    "        dailyemotiondict[\"negemo\"]=v\n",
    "    for v in scores_df.affect:\n",
    "        dailyemotiondict[\"affect\"]=v\n",
    "    for v in scores_df.swear:\n",
    "        dailyemotiondict[\"swear\"]=v\n",
    "    for v in scores_df.anx:\n",
    "        dailyemotiondict[\"anxiety\"]=v\n",
    "    for v in scores_df.sad:\n",
    "        dailyemotiondict[\"sad\"]=v\n",
    "    # ---------\n",
    "    dailyrelationdict = {}\n",
    "    for v in scores_df.relationIndex:\n",
    "        dailyrelationdict[\"relationIndex\"]=v\n",
    "    for v in scores_df.money:\n",
    "        dailyrelationdict[\"money\"]=v\n",
    "    for v in scores_df.work:\n",
    "        dailyrelationdict[\"work\"]=v\n",
    "    # ---------\n",
    "    dailyeconomydict = {}\n",
    "    for v in scores_df.economyIndex:\n",
    "        dailyeconomydict[\"economyIndex\"]=v\n",
    "    for v in scores_df.money:\n",
    "        dailyeconomydict[\"money\"]=v\n",
    "    for v in scores_df.work:\n",
    "        dailyeconomydict[\"work\"]=v\n",
    "    # ---------\n",
    "    dailypoliticaldict = {}\n",
    "    for v in scores_df.politicalIndex:\n",
    "        dailypoliticaldict[\"politicalIndex\"]=v\n",
    "    for v in scores_df.power:\n",
    "        dailypoliticaldict[\"power\"]=v\n",
    "    for v in scores_df.cause:\n",
    "        dailypoliticaldict[\"cause\"]=v\n",
    "    for v in scores_df.certain:\n",
    "        dailypoliticaldict[\"certain\"]=v\n",
    "    for v in scores_df.insight:\n",
    "        dailypoliticaldict[\"insight\"]=v\n",
    "    for v in scores_df.compare:\n",
    "        dailypoliticaldict[\"compare\"]=v\n",
    "    for v in scores_df.risk:\n",
    "        dailypoliticaldict[\"risk\"]=v\n",
    "    for v in scores_df.interrog:\n",
    "        dailypoliticaldict[\"interrog\"]=v\n",
    "    for v in scores_df.focusfuture:\n",
    "        dailypoliticaldict[\"focusfuture\"]=v\n",
    "    for v in scores_df.relig:\n",
    "        dailypoliticaldict[\"relig\"]=v\n",
    "    for v in scores_df.tentat:\n",
    "        dailypoliticaldict[\"tentat\"]=v\n",
    "    for v in scores_df.quant:\n",
    "        dailypoliticaldict[\"quant\"]=v\n",
    "    # ---------\n",
    "\n",
    "    \n",
    "    dailydatadict[\"disease\"] = dailydiseasedict\n",
    "    dailydatadict[\"emotion\"] = dailyemotiondict\n",
    "    dailydatadict[\"relation\"] = dailyrelationdict\n",
    "    dailydatadict[\"economy\"] = dailyeconomydict\n",
    "    dailydatadict[\"politiical\"] = dailypoliticaldict\n",
    "    \n",
    "    twitter_data[day]= dailydatadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data-delivery-to-frontend.txt', 'w') as file:\n",
    "    file.write(str(twitter_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
